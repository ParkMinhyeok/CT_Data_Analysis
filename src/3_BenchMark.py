

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder

# ëª¨ë¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

# --- 1. ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ ---
try:
    df = pd.read_csv('training_data.csv', parse_dates=['ì¼ì‹œ'])
except FileNotFoundError:
    print("âŒ 'training_data.csv' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ì „ ë‹¨ê³„ì˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    exit()

# ë¼ë²¨ ì¸ì½”ë”© ('Rest' -> 0, 'Run' -> 1)
# LabelEncoderë¥¼ ì‚¬ìš©í•˜ì—¬ í´ë˜ìŠ¤ ì´ë¦„ì„ ê¸°ì–µí•˜ê²Œ í•¨
le = LabelEncoder()
df['label_encoded'] = le.fit_transform(df['label'])

X = df[['ì¼ì‹œ', 'ì˜¨ë„']] # ì‹œê°í™”ë¥¼ ìœ„í•´ 'ì¼ì‹œ'ë„ í¬í•¨
y = df['label_encoded']

# í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)


# --- 2. ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ (XGBoostë§Œ ì„ íƒ) ---
print("--- [ XGBoost ] ëª¨ë¸ í•™ìŠµ ì‹œì‘ ---")
best_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')
# í•™ìŠµ ì‹œì—ëŠ” 'ì¼ì‹œ' ì—´ì„ ì œì™¸í•˜ê³  í•™ìŠµ
best_model.fit(X_train[['ì˜¨ë„']], y_train)

# ì˜ˆì¸¡ ì‹œì—ë„ 'ì¼ì‹œ' ì—´ ì œì™¸
predictions = best_model.predict(X_test[['ì˜¨ë„']])
print("--- [ XGBoost ] ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ì™„ë£Œ ---\n")

print("="*50)
print("âœ¨ XGBoost ëª¨ë¸ í‰ê°€ ê²°ê³¼ âœ¨")
print("="*50)
# classification_reportë¥¼ ìœ„í•´ ë¼ë²¨ ì´ë¦„ì„ ë‹¤ì‹œ ë¬¸ìë¡œ ë³€í™˜
y_test_labels = le.inverse_transform(y_test)
predictions_labels = le.inverse_transform(predictions)
print(classification_report(y_test_labels, predictions_labels))


# --- 3. ì‹œê°í™”ë¥¼ ìœ„í•œ ë°ì´í„° ì¤€ë¹„ ---
# X_testì— ì‹¤ì œ ë¼ë²¨ê³¼ ì˜ˆì¸¡ ë¼ë²¨ì„ í•©ì¹˜ê¸°
plot_df = X_test.copy()
plot_df['true_label'] = le.inverse_transform(y_test)
plot_df['predicted_label'] = le.inverse_transform(predictions)
plot_df.sort_values(by='ì¼ì‹œ', inplace=True) # ì‹œê°„ ìˆœìœ¼ë¡œ ì •ë ¬


# --- 4. ìµœì¢… ê²°ê³¼ ì‹œê°í™” ---
print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì‹œê°í™” ì¤‘...")

# 2ê°œì˜ ê·¸ë˜í”„ë¥¼ ë‚˜ë€íˆ ê·¸ë¦¬ê¸°
fig, axes = plt.subplots(2, 1, figsize=(20, 12), sharex=True)
fig.suptitle('XGBoost ëª¨ë¸ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì‹œê°í™”', fontsize=20)

# ìƒ‰ìƒ íŒ”ë ˆíŠ¸ ì •ì˜
palette = {'Rest': 'royalblue', 'Run': 'crimson'}

# ì²« ë²ˆì§¸ ê·¸ë˜í”„: ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼
sns.scatterplot(data=plot_df, x='ì¼ì‹œ', y='ì˜¨ë„', hue='predicted_label', palette=palette, s=15, ax=axes[0])
axes[0].set_title('ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ (Model Predictions)', fontsize=15)
axes[0].set_ylabel('ì˜¨ë„')
axes[0].grid(True, linestyle='--', alpha=0.6)
axes[0].legend(title='ì˜ˆì¸¡ëœ ë¼ë²¨')

# ë‘ ë²ˆì§¸ ê·¸ë˜í”„: ì‹¤ì œ ì •ë‹µ
sns.scatterplot(data=plot_df, x='ì¼ì‹œ', y='ì˜¨ë„', hue='true_label', palette=palette, s=15, ax=axes[1])
axes[1].set_title('ì‹¤ì œ ì •ë‹µ (Ground Truth)', fontsize=15)
axes[1].set_xlabel('ì‹œê°„')
axes[1].set_ylabel('ì˜¨ë„')
axes[1].grid(True, linestyle='--', alpha=0.6)
axes[1].legend(title='ì‹¤ì œ ë¼ë²¨')

plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()
