import torch
import torch.nn as nn
from torch.utils.data import DataLoader
import numpy as np
import pandas as pd
import joblib
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.dates as mdates

# --- 1. ì„¤ì • ë° íŒŒë¼ë¯¸í„° ---
TEST_CSV_PATH = 'labeled_test_data.csv'
MODEL_PATH = 'best_model.pt'
SCALER_PATH = 'scaler.pkl'

# ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° (í•™ìŠµ ì½”ë“œì™€ ì •í™•íˆ ì¼ì¹˜)
WINDOW_SIZE = 200
INPUT_SIZE = 1
HIDDEN_SIZE = 32
NUM_LAYERS = 2
NUM_CLASSES = 2 # Run(1) vs Rest(0) ì´ì§„ ë¶„ë¥˜
BATCH_SIZE = 64

# --- 2. í•™ìŠµ ì½”ë“œì™€ ë™ì¼í•œ ëª¨ë¸ ë° í•¨ìˆ˜ ì •ì˜ ---
class LSTMClassifier(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, num_classes):
        super(LSTMClassifier, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers,
                              batch_first=True, dropout=0.3, bidirectional=True)
        self.fc = nn.Linear(hidden_size * 2, num_classes)
    def forward(self, x):
        x = x.unsqueeze(-1)
        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(x.device)
        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(x.device)
        out, _ = self.lstm(x, (h0, c0))
        out = self.fc(out[:, -1, :])
        return out

def create_sequences(X, y, window_size):
    dataX, dataY = [], []
    for i in range(len(X) - window_size):
        dataX.append(X[i:(i + window_size), 0])
        dataY.append(y[i + window_size])
    return np.array(dataX), np.array(dataY)

# --- 3. í…ŒìŠ¤íŠ¸ ì¤€ë¹„ ---
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f'Using device: {device}')

model = LSTMClassifier(INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS, NUM_CLASSES).to(device)
try:
    model.load_state_dict(torch.load(MODEL_PATH))
    scaler = joblib.load(SCALER_PATH)
except FileNotFoundError as e:
    print(f"ğŸš¨ ì˜¤ë¥˜: {e}")
    print("ë¨¼ì € í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ì—¬ 'best_model.pt'ì™€ 'scaler.pkl' íŒŒì¼ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.")
    exit()

model.eval()

df_test = pd.read_csv(TEST_CSV_PATH)
df_test['ì¼ì‹œ'] = pd.to_datetime(df_test['ì¼ì‹œ'])
features = df_test[['ì •ê·œí™”_ì˜¨ë„']].values
labels = df_test['label'].values
scaled_features = scaler.transform(features)
X_test, y_test = create_sequences(scaled_features, labels, WINDOW_SIZE)
test_loader = DataLoader(dataset=list(zip(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).long())),
                         batch_size=BATCH_SIZE, shuffle=False)

# --- 4. ëª¨ë¸ ì˜ˆì¸¡ ë° í‰ê°€ ---
print("--- ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹œì‘ ---")
all_preds = []
all_labels = []
with torch.no_grad():
    for sequences, labels in test_loader:
        sequences = sequences.to(device)
        outputs = model(sequences)
        _, predicted = torch.max(outputs.data, 1)
        all_preds.extend(predicted.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

# --- 5. ê²°ê³¼ ë¶„ì„ ---
print("\n--- ë¶„ë¥˜ ë¦¬í¬íŠ¸ (Classification Report) ---")
target_names = ['Rest (0)', 'Run (1)']
print(classification_report(all_labels, all_preds, target_names=target_names, zero_division=0))

print("\n--- í˜¼ë™ í–‰ë ¬ (Confusion Matrix) ---")
cm = confusion_matrix(all_labels, all_preds)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')

# [ìˆ˜ì •] í˜¼ë™ í–‰ë ¬ ê·¸ë˜í”„ë¥¼ jpg íŒŒì¼ë¡œ ì €ì¥
plt.savefig('confusion_matrix.jpg', dpi=300, bbox_inches='tight')
print("âœ… 'confusion_matrix.jpg' íŒŒì¼ ì €ì¥ ì™„ë£Œ")
plt.show()


# --- 6. ê²°ê³¼ ì‹œê°í™” ---
print("\n--- ê²°ê³¼ ì‹œê°í™” ì‹œì‘ ---")
df_plot = df_test.iloc[WINDOW_SIZE:].copy()
df_plot['predicted_label'] = all_preds

plt.style.use('seaborn-v0_8-whitegrid')
fig, ax = plt.subplots(figsize=(20, 8))
ax.plot(df_plot['ì¼ì‹œ'], df_plot['ì •ê·œí™”_ì˜¨ë„'], color='lightgray', alpha=0.7, label='Normalized Temperature', zorder=1)
for _, g in df_plot[df_plot['label'] == 1].groupby((df_plot['label'] != df_plot['label'].shift()).cumsum()):
    ax.axvspan(g['ì¼ì‹œ'].iloc[0], g['ì¼ì‹œ'].iloc[-1], color='blue', alpha=0.2, label='_nolegend_')
pred_run = df_plot[df_plot['predicted_label'] == 1]
ax.scatter(pred_run['ì¼ì‹œ'], pred_run['ì •ê·œí™”_ì˜¨ë„'], color='red', marker='o', s=10, label='Predicted Run', zorder=5)
handles, labels = ax.get_legend_handles_labels()
from matplotlib.patches import Patch
handles.append(Patch(facecolor='blue', alpha=0.2))
labels.append('True Run')
ax.legend(handles, labels, fontsize=12)
ax.set_title('Model Prediction vs True Labels', fontsize=18)
ax.set_xlabel('Time', fontsize=12)
ax.set_ylabel('Normalized Temperature', fontsize=12)
ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d %H:%M'))
plt.xticks(rotation=45)
plt.tight_layout()

# [ìˆ˜ì •] ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™” ê·¸ë˜í”„ë¥¼ jpg íŒŒì¼ë¡œ ì €ì¥
plt.savefig('prediction_visualization.jpg', dpi=300, bbox_inches='tight')
print("âœ… 'prediction_visualization.jpg' íŒŒì¼ ì €ì¥ ì™„ë£Œ")
plt.show()